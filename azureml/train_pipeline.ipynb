{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'iris-classification-training'\n",
    "upload_sample_data = False\n",
    "register_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (cryptography 2.9.2 (c:\\program files (x86)\\microsoft visual studio\\shared\\anaconda3_64\\lib\\site-packages), Requirement.parse('cryptography<4.0.0,>=3.3.1; extra == \"crypto\"'), {'PyJWT'}).\n"
     ]
    }
   ],
   "source": [
    "#import required packages to build the pipeline artifact\n",
    "from azureml.core import Experiment, Dataset\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget, DatabricksCompute\n",
    "from azureml.core.datastore import Datastore\n",
    "from azureml.core.runconfig import CondaDependencies, RunConfiguration\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.core import Pipeline, PipelineData, PortDataReference\n",
    "from azureml.pipeline.steps import PythonScriptStep, DatabricksStep\n",
    "from azureml.core.model import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\nIf you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\nPlease refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "found existing compute target.\nAml Compute attached\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "aml_compute_target = \"cpu-cluster\"\n",
    "try:\n",
    "    aml_compute = AmlCompute(ws, aml_compute_target)\n",
    "    print(\"found existing compute target.\")\n",
    "except ComputeTargetException:\n",
    "    print(\"creating new compute target\")\n",
    "    \n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\",\n",
    "                                                                min_nodes = 0, \n",
    "                                                                max_nodes = 4)    \n",
    "    aml_compute = ComputeTarget.create(ws, aml_compute_target, provisioning_config)\n",
    "    aml_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "print(\"Aml Compute attached\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Default Blobstore's name: workspaceblobstore\nDefault Blobstore's container name: azureml-blobstore-3ebbce3f-1760-43ec-942d-7ed495b50dbe\n"
     ]
    }
   ],
   "source": [
    "# Getting the default blob store (Datastore) for the Azure ML workspace\n",
    "ds = ws.get_default_datastore()\n",
    "print(\"Default Blobstore's name: {}\".format(ds.name))\n",
    "print(\"Default Blobstore's container name: {}\".format(ds.container_name))"
   ]
  },
  {
   "source": [
    "Upload and register the iris data to Azure ML to be used in pipelines"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload iris data\n",
    "if upload_sample_data:\n",
    "    ds.upload_files(['../sample_data.csv'], target_path='/data', overwrite=True, show_progress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if register_data:\n",
    "    # create target dataset \n",
    "    registereddata = Dataset.Tabular.from_delimited_files(ds.path('/data/sample_data.csv'))\n",
    "    # NO TIMESTAMP COLUMN EXISTS\n",
    "    #target = target.with_timestamp_columns('datetime')\n",
    "    # register the target dataset\n",
    "    registereddata = registereddata.register(ws, 'iris-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.get_by_name(ws,name='iris-data',version='latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DataReference object created\nPipelineData object created for models\n"
     ]
    }
   ],
   "source": [
    "dataset_ref = DataReference(\n",
    "    datastore=ds,\n",
    "    data_reference_name='irisdata',\n",
    "    path_on_datastore=\"data/sample_data.csv\")\n",
    "print(\"DataReference object created\")\n",
    "\n",
    "\n",
    "model_output = PipelineData(\"model_output\",datastore=ds)\n",
    "print(\"PipelineData object created for models\")"
   ]
  },
  {
   "source": [
    "#### Create Pipeline Steps to be executed each time the pipeline runs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "\n",
    "# create a new runconfig object\n",
    "run_config = RunConfiguration()\n",
    "\n",
    "# enable Docker \n",
    "run_config.environment.docker.enabled = True\n",
    "# set Docker base image to the default CPU-based image\n",
    "run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "# use conda_dependencies.yml to create a conda environment in the Docker image for execution\n",
    "run_config.environment.python.user_managed_dependencies = False\n",
    "\n",
    "# specify CondaDependencies obj\n",
    "run_config.environment.python.conda_dependencies = CondaDependencies.create(\n",
    "    pip_packages=['azureml-sdk','sklearn', 'scipy', 'numpy', 'pandas'],\n",
    "    conda_packages=['matplotlib'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "trainingStep created\n"
     ]
    }
   ],
   "source": [
    "# run the transformation script to produce the intermediate data that will go to the inferencing step\n",
    "trainingScript = PythonScriptStep(\n",
    "    script_name=\"iris_supervised_model.py\", \n",
    "    inputs=[dataset_ref],\n",
    "    outputs=[model_output],\n",
    "    compute_target=aml_compute, \n",
    "    source_directory=\".\",\n",
    "    runconfig=run_config\n",
    ")\n",
    "print(\"trainingStep created\")"
   ]
  },
  {
   "source": [
    "### Using the output\n",
    "In the previous PythonScriptStep, a PipelineOutputFileDataset was created as an output and assigned to \"model_output\". Doc is here: https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipeline_output_dataset.pipelineoutputfiledataset?view=azure-ml-py"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "registerModelStep created\n"
     ]
    }
   ],
   "source": [
    "# run the transformation script to produce the intermediate data that will go to the inferencing step\n",
    "registerModelStep = PythonScriptStep(\n",
    "    script_name=\"register_model.py\", \n",
    "    arguments=[\"--model_name\", \"iris_classifier_model\",\"--training_step_name\",\"iris_supervised_model.py\"],\n",
    "    inputs=[dataset_ref,model_output],\n",
    "    #outputs=[model_output],\n",
    "    compute_target=aml_compute, \n",
    "    source_directory=\".\",\n",
    "    runconfig=run_config\n",
    ")\n",
    "print(\"registerModelStep created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pipeline is built\n"
     ]
    }
   ],
   "source": [
    "iris_train_pipeline = Pipeline(workspace=ws, steps=[trainingScript,registerModelStep])\n",
    "print (\"Pipeline is built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Created step iris_supervised_model.py [997f2cac][cd112aa4-0e9c-444c-85ee-0d2edffbfc86], (This step will run and generate new outputs)\n",
      "Created step register_model.py [f3cc70c8][740c2c84-b375-40c4-a143-7bb9560d0b0f], (This step will run and generate new outputs)\n",
      "Using data reference irisdata for StepId [32c12e24][77fa1314-ea57-4a57-ab61-5f2222c7f6c1], (Consumers of this data are eligible to reuse prior runs.)Using data reference irisdata for StepId [7f874f8f][77fa1314-ea57-4a57-ab61-5f2222c7f6c1], (Consumers of this data are eligible to reuse prior runs.)\n",
      "\n",
      "Submitted PipelineRun 49fc358e-d8dc-4ce4-8c66-005a23adcd49\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/iris-classification-training/runs/49fc358e-d8dc-4ce4-8c66-005a23adcd49?wsid=/subscriptions/31e77061-7c45-4325-a0ec-1d348d195b23/resourcegroups/Synapse-WS-L400/workspaces/amlworkspacesjh\n",
      "Pipeline is submitted for execution\n"
     ]
    }
   ],
   "source": [
    "exp = Experiment(ws,experiment_name)\n",
    "exp.set_tags({'automl':'no'})\n",
    "\n",
    "pipeline_run1 = exp.submit(iris_train_pipeline)\n",
    "print(\"Pipeline is submitted for execution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PipelineRunId: 16c06744-6308-4a5c-9e4e-07db39b4dc8c\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/iris-classification-training/runs/16c06744-6308-4a5c-9e4e-07db39b4dc8c?wsid=/subscriptions/31e77061-7c45-4325-a0ec-1d348d195b23/resourcegroups/Synapse-WS-L400/workspaces/amlworkspacesjh\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: a1aef280-8ccc-426d-869b-64c0c749b84d\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/iris-classification-training/runs/a1aef280-8ccc-426d-869b-64c0c749b84d?wsid=/subscriptions/31e77061-7c45-4325-a0ec-1d348d195b23/resourcegroups/Synapse-WS-L400/workspaces/amlworkspacesjh\n",
      "StepRun( iris_supervised_model.py ) Status: NotStarted\n",
      "StepRun( iris_supervised_model.py ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_90cca1a8cb07d7fdf218de63ed5f09e8a276af0675218dbcce4744c8ac9dad02_d.txt\n",
      "========================================================================================================================\n",
      "2021-02-18T03:57:46Z Starting output-watcher...\n",
      "2021-02-18T03:57:46Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-02-18T03:57:47Z Executing 'Copy ACR Details file' on 10.0.0.5\n",
      "2021-02-18T03:57:47Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_dec0d3c1f1f13a3992b990d25cac0a66\n",
      "be8ec4e48d7f: Pulling fs layer\n",
      "33b8b485aff0: Pulling fs layer\n",
      "d887158cc58c: Pulling fs layer\n",
      "05895bb28c18: Pulling fs layer\n",
      "baf7ab26f516: Pulling fs layer\n",
      "181182e3c9cf: Pulling fs layer\n",
      "d584ef274e55: Pulling fs layer\n",
      "c445dda55407: Pulling fs layer\n",
      "699b75ff4717: Pulling fs layer\n",
      "b177109c9d16: Pulling fs layer\n",
      "59cea07bb66c: Pulling fs layer\n",
      "d54d011de0e3: Pulling fs layer\n",
      "93b5780deceb: Pulling fs layer\n",
      "eb2f250e4b14: Pulling fs layer\n",
      "306cd6ef9577: Pulling fs layer\n",
      "01c2a601cf48: Pulling fs layer\n",
      "ff3b0f03863b: Pulling fs layer\n",
      "165a6907b6aa: Pulling fs layer\n",
      "b177109c9d16: Waiting\n",
      "59cea07bb66c: Waiting\n",
      "d54d011de0e3: Waiting\n",
      "93b5780deceb: Waiting\n",
      "eb2f250e4b14: Waiting\n",
      "306cd6ef9577: Waiting\n",
      "01c2a601cf48: Waiting\n",
      "ff3b0f03863b: Waiting\n",
      "165a6907b6aa: Waiting\n",
      "05895bb28c18: Waiting\n",
      "baf7ab26f516: Waiting\n",
      "181182e3c9cf: Waiting\n",
      "d584ef274e55: Waiting\n",
      "c445dda55407: Waiting\n",
      "699b75ff4717: Waiting\n",
      "33b8b485aff0: Verifying Checksum\n",
      "33b8b485aff0: Download complete\n",
      "d887158cc58c: Verifying Checksum\n",
      "d887158cc58c: Download complete\n",
      "05895bb28c18: Verifying Checksum\n",
      "05895bb28c18: Download complete\n",
      "be8ec4e48d7f: Verifying Checksum\n",
      "be8ec4e48d7f: Download complete\n",
      "181182e3c9cf: Verifying Checksum\n",
      "181182e3c9cf: Download complete\n",
      "d584ef274e55: Download complete\n",
      "baf7ab26f516: Verifying Checksum\n",
      "baf7ab26f516: Download complete\n",
      "c445dda55407: Verifying Checksum\n",
      "c445dda55407: Download complete\n",
      "b177109c9d16: Verifying Checksum\n",
      "b177109c9d16: Download complete\n",
      "d54d011de0e3: Verifying Checksum\n",
      "d54d011de0e3: Download complete\n",
      "be8ec4e48d7f: Pull complete\n",
      "59cea07bb66c: Verifying Checksum\n",
      "59cea07bb66c: Download complete\n",
      "93b5780deceb: Verifying Checksum\n",
      "93b5780deceb: Download complete\n",
      "33b8b485aff0: Pull complete\n",
      "d887158cc58c: Pull complete\n",
      "05895bb28c18: Pull complete\n",
      "699b75ff4717: Verifying Checksum\n",
      "699b75ff4717: Download complete\n",
      "306cd6ef9577: Verifying Checksum\n",
      "306cd6ef9577: Download complete\n",
      "eb2f250e4b14: Verifying Checksum\n",
      "eb2f250e4b14: Download complete\n",
      "01c2a601cf48: Verifying Checksum\n",
      "01c2a601cf48: Download complete\n",
      "165a6907b6aa: Verifying Checksum\n",
      "165a6907b6aa: Download complete\n",
      "ff3b0f03863b: Verifying Checksum\n",
      "ff3b0f03863b: Download complete\n",
      "baf7ab26f516: Pull complete\n",
      "181182e3c9cf: Pull complete\n",
      "d584ef274e55: Pull complete\n",
      "c445dda55407: Pull complete\n",
      "699b75ff4717: Pull complete\n",
      "b177109c9d16: Pull complete\n",
      "59cea07bb66c: Pull complete\n",
      "d54d011de0e3: Pull complete\n",
      "93b5780deceb: Pull complete\n",
      "eb2f250e4b14: Pull complete\n",
      "306cd6ef9577: Pull complete\n",
      "01c2a601cf48: Pull complete\n",
      "ff3b0f03863b: Pull complete\n",
      "165a6907b6aa: Pull complete\n",
      "Digest: sha256:89148eecf22d8dd3189501f3c8d69d9065c41abf97117a4f2b0654adbf5c5bdf\n",
      "Status: Downloaded newer image for 3ebbce3f176043ec942d7ed495b50dbe.azurecr.io/azureml/azureml_dec0d3c1f1f13a3992b990d25cac0a66:latest\n",
      "3ebbce3f176043ec942d7ed495b50dbe.azurecr.io/azureml/azureml_dec0d3c1f1f13a3992b990d25cac0a66:latest\n",
      "2021-02-18T03:59:23Z Check if container a1aef280-8ccc-426d-869b-64c0c749b84d already exist exited with 0, \n",
      "\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2021/02/18 03:59:43 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/info\n",
      "2021/02/18 03:59:43 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n",
      "[2021-02-18T03:59:44.819584] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['iris_supervised_model.py'])\n",
      "Script type = None\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 117\n",
      "[2021-02-18T03:59:46.707762] Entering Run History Context Manager.\n",
      "[2021-02-18T03:59:49.114999] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/amlworkspacesjh/azureml/a1aef280-8ccc-426d-869b-64c0c749b84d/mounts/workspaceblobstore/azureml/a1aef280-8ccc-426d-869b-64c0c749b84d\n",
      "[2021-02-18T03:59:49.115399] Preparing to call script [iris_supervised_model.py] with arguments:[]\n",
      "[2021-02-18T03:59:49.115469] After variable expansion, calling script [iris_supervised_model.py] with arguments:[]\n",
      "\n",
      "======================================\n",
      "Python:      3.6.2 |Anaconda, Inc.| (default, Oct  5 2017, 07:59:26) \n",
      "[GCC 7.2.0]\n",
      "scipy:       1.5.4\n",
      "numpy:       1.19.5\n",
      "matplotlib:  3.3.1\n",
      "pandas:      1.1.5\n",
      "sklearn:     0.24.1\n",
      "======================================\n",
      "X_train: (120, 4)\n",
      "X_validation: (30, 4)\n",
      "Y_train: (120,)\n",
      "Y_validation: (30,)\n",
      "======================================\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 117\n",
      "\n",
      "\n",
      "[2021-02-18T03:59:51.104091] The experiment failed. Finalizing run...\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 117\n",
      "Cleaning up all outstanding Run operations, waiting 900.0 seconds\n",
      "3 items cleaning up...\n",
      "Cleanup took 0.8320960998535156 seconds\n",
      "Traceback (most recent call last):\n",
      "  File \"iris_supervised_model.py\", line 89, in <module>\n",
      "    run.log_confusion_matrix('Confusion matrix '+name, confusion_matrix(Y_train, model.predict(X_train)))\n",
      "  File \"/azureml-envs/azureml_4a320c4a4735158f48a1692ae678e245/lib/python3.6/site-packages/sklearn/linear_model/_base.py\", line 309, in predict\n",
      "    scores = self.decision_function(X)\n",
      "  File \"/azureml-envs/azureml_4a320c4a4735158f48a1692ae678e245/lib/python3.6/site-packages/sklearn/linear_model/_base.py\", line 282, in decision_function\n",
      "    check_is_fitted(self)\n",
      "  File \"/azureml-envs/azureml_4a320c4a4735158f48a1692ae678e245/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/azureml-envs/azureml_4a320c4a4735158f48a1692ae678e245/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 1041, in check_is_fitted\n",
      "    raise NotFittedError(msg % {'name': type(estimator).__name__})\n",
      "sklearn.exceptions.NotFittedError: This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
      "\n",
      "[2021-02-18T03:59:52.824536] Finished context manager injector with Exception.\n",
      "2021/02/18 03:59:56 Failed to parse control script error: /mnt/batch/tasks/workitems/7b732ce5-319a-40ee-9ed5-c49f1359642c/job-1/a1aef280-8ccc-426d-8_39fa6aa5-960a-454d-b360-053cdefc763e/wd/runTaskLetTask_error.json to json File /mnt/batch/tasks/workitems/7b732ce5-319a-40ee-9ed5-c49f1359642c/job-1/a1aef280-8ccc-426d-8_39fa6aa5-960a-454d-b360-053cdefc763e/wd/runTaskLetTask_error.json doesn't exist\n",
      "2021/02/18 03:59:56 Failed to run the wrapper cmd with err: exit status 1\n",
      "2021/02/18 03:59:56 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n",
      "2021/02/18 03:59:56 mpirun version string: {\n",
      "Intel(R) MPI Library for Linux* OS, Version 2018 Update 3 Build 20180411 (id: 18329)\n",
      "Copyright 2003-2018 Intel Corporation.\n",
      "}\n",
      "2021/02/18 03:59:56 MPI publisher: intel ; version: 2018\n",
      "2021/02/18 03:59:56 Process Exiting with Code:  1\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_90cca1a8cb07d7fdf218de63ed5f09e8a276af0675218dbcce4744c8ac9dad02_d.txt\n",
      "===============================================================================================================\n",
      "[2021-02-18T03:59:57.498101] Entering job release\n",
      "[2021-02-18T03:59:58.995051] Starting job release\n",
      "[2021-02-18T03:59:59.009059] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 213\n",
      "[2021-02-18T03:59:59.011240] job release stage : upload_datastore starting...\n",
      "[2021-02-18T03:59:59.011802] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-02-18T03:59:59.012266] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-02-18T03:59:59.012379] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-02-18T03:59:59.027192] job release stage : execute_job_release starting...\n",
      "[2021-02-18T03:59:59.027863] Entering context manager injector.\n",
      "[2021-02-18T03:59:59.329025] job release stage : execute_job_release completed...\n",
      "[2021-02-18T03:59:59.429147] job release stage : upload_datastore completed...\n",
      "[2021-02-18T03:59:59.781532] job release stage : send_run_telemetry starting...\n",
      "[2021-02-18T03:59:59.975655] get vm size and vm region successfully.\n",
      "[2021-02-18T04:00:00.147951] get compute meta data successfully.\n",
      "[2021-02-18T04:00:01.179925] post artifact meta request successfully.\n",
      "[2021-02-18T04:00:01.231350] upload compute record artifact successfully.\n",
      "[2021-02-18T04:00:01.438188] job release stage : send_run_telemetry completed...\n",
      "[2021-02-18T04:00:01.438503] Job release is complete\n",
      "\n",
      "StepRun(iris_supervised_model.py) Execution Summary\n",
      "====================================================\n",
      "StepRun( iris_supervised_model.py ) Status: Failed\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ActivityFailedException",
     "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",\n        \"messageFormat\": \"{Message}\",\n        \"messageParameters\": {\n            \"Message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\"\n        },\n        \"details\": [],\n        \"innerError\": {\n            \"code\": \"BadArgument\",\n            \"innerError\": {\n                \"code\": \"AmlComputeBadRequest\"\n            }\n        }\n    },\n    \"correlation\": {\n        \"operation\": null,\n        \"request\": \"3cd01b106aa0d0aa\"\n    },\n    \"environment\": \"eastus2\",\n    \"location\": \"eastus2\",\n    \"time\": \"2021-02-18T04:00:19.182802Z\",\n    \"componentName\": \"execution-worker\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"AzureMLCompute job failed.\\\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\\\n\\\\tReason: Job failed with non-zero exit Code\\\",\\n        \\\"messageFormat\\\": \\\"{Message}\\\",\\n        \\\"messageParameters\\\": {\\n            \\\"Message\\\": \\\"AzureMLCompute job failed.\\\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\\\n\\\\tReason: Job failed with non-zero exit Code\\\"\\n        },\\n        \\\"details\\\": [],\\n        \\\"innerError\\\": {\\n            \\\"code\\\": \\\"BadArgument\\\",\\n            \\\"innerError\\\": {\\n                \\\"code\\\": \\\"AmlComputeBadRequest\\\"\\n            }\\n        }\\n    },\\n    \\\"correlation\\\": {\\n        \\\"operation\\\": null,\\n        \\\"request\\\": \\\"3cd01b106aa0d0aa\\\"\\n    },\\n    \\\"environment\\\": \\\"eastus2\\\",\\n    \\\"location\\\": \\\"eastus2\\\",\\n    \\\"time\\\": \\\"2021-02-18T04:00:19.182802Z\\\",\\n    \\\"componentName\\\": \\\"execution-worker\\\"\\n}\"\n    }\n}",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-287e6c82988f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpipeline_run1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\azureml\\pipeline\\core\\run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[1;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[0;32m    293\u001b[0m                             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                                 step_run.wait_for_completion(timeout_seconds=timeout_seconds - time_elapsed,\n\u001b[1;32m--> 295\u001b[1;33m                                                              raise_on_error=raise_on_error)\n\u001b[0m\u001b[0;32m    296\u001b[0m                             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m                                 \u001b[1;31m# If there are package conflicts in the user's environment, the run rehydration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\azureml\\pipeline\\core\\run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[1;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[0;32m    735\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m                 return self._stream_run_output(timeout_seconds=timeout_seconds,\n\u001b[1;32m--> 737\u001b[1;33m                                                raise_on_error=raise_on_error)\n\u001b[0m\u001b[0;32m    738\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m                 \u001b[0merror_message\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"The output streaming for the run interrupted.\\n\"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\azureml\\pipeline\\core\\run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[1;34m(self, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[0;32m    823\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 825\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mActivityFailedException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_details\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_details\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",\n        \"messageFormat\": \"{Message}\",\n        \"messageParameters\": {\n            \"Message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\"\n        },\n        \"details\": [],\n        \"innerError\": {\n            \"code\": \"BadArgument\",\n            \"innerError\": {\n                \"code\": \"AmlComputeBadRequest\"\n            }\n        }\n    },\n    \"correlation\": {\n        \"operation\": null,\n        \"request\": \"3cd01b106aa0d0aa\"\n    },\n    \"environment\": \"eastus2\",\n    \"location\": \"eastus2\",\n    \"time\": \"2021-02-18T04:00:19.182802Z\",\n    \"componentName\": \"execution-worker\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"AzureMLCompute job failed.\\\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\\\n\\\\tReason: Job failed with non-zero exit Code\\\",\\n        \\\"messageFormat\\\": \\\"{Message}\\\",\\n        \\\"messageParameters\\\": {\\n            \\\"Message\\\": \\\"AzureMLCompute job failed.\\\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\\\n\\\\tReason: Job failed with non-zero exit Code\\\"\\n        },\\n        \\\"details\\\": [],\\n        \\\"innerError\\\": {\\n            \\\"code\\\": \\\"BadArgument\\\",\\n            \\\"innerError\\\": {\\n                \\\"code\\\": \\\"AmlComputeBadRequest\\\"\\n            }\\n        }\\n    },\\n    \\\"correlation\\\": {\\n        \\\"operation\\\": null,\\n        \\\"request\\\": \\\"3cd01b106aa0d0aa\\\"\\n    },\\n    \\\"environment\\\": \\\"eastus2\\\",\\n    \\\"location\\\": \\\"eastus2\\\",\\n    \\\"time\\\": \\\"2021-02-18T04:00:19.182802Z\\\",\\n    \\\"componentName\\\": \\\"execution-worker\\\"\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "pipeline_run1.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Steps\n",
    "model_type=None\n",
    "model_accuracy=None\n",
    "run_id=0\n",
    "for step in pipeline_run1.get_steps():\n",
    "    print(\"Outputs of step \" + step.name)\n",
    "    \n",
    "    # Get a dictionary of StepRunOutputs with the output name as the key \n",
    "    output_dict = step.get_outputs()\n",
    "\n",
    "    if step.name == 'iris_supervised_model.py':\n",
    "        #step.download_file('model_output',output_file_path='.')\n",
    "        model_type = step.get_properties()['best_model']\n",
    "        model_accuracy = float(step.get_properties()['accuracy'])\n",
    "        run_id = step.id\n",
    "    for name, output in output_dict.items():\n",
    "        \n",
    "        output_reference = output.get_port_data_reference() # Get output port data reference\n",
    "        print(\"\\tname: \" + name)\n",
    "        print(\"\\tdatastore: \" + output_reference.datastore_name)\n",
    "        print(\"\\tpath on datastore: \" + output_reference.path_on_datastore)\n",
    "\n",
    "            \n"
   ]
  },
  {
   "source": [
    "## Model Registration\n",
    "The below code is an example of how to register a model, in the automated code, this is completed in register_model.py instead of train_pipeline.py"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from azureml.core import Model\n",
    "from azureml.core.resource_configuration import ResourceConfiguration\n",
    "import sklearn\n",
    "\n",
    "model_name = 'iris-model'\n",
    "model_path = 'model_output'\n",
    "\n",
    "try:\n",
    "    model = Model(ws, model_name)\n",
    "    current_accuracy = float(model.properties[\"accuracy\"])\n",
    "except:\n",
    "    current_accuracy = 0\n",
    "\n",
    "print(\"current accuracy\",current_accuracy)\n",
    "if model_accuracy > current_accuracy:\n",
    "    print(\"model is better\")\n",
    "    model = Model.register(workspace=ws,\n",
    "                       model_name=model_name,                # Name of the registered model in your workspace.\n",
    "                       model_path=model_path,  # Local file to upload and register as a model.\n",
    "                       model_framework=Model.Framework.SCIKITLEARN,  # Framework used to create the model.\n",
    "                       model_framework_version=sklearn.__version__,  # Version of scikit-learn used to create the model.\n",
    "                       sample_input_dataset=dataset,\n",
    "                       #sample_output_dataset=output_dataset,\n",
    "                       resource_configuration=ResourceConfiguration(cpu=1, memory_in_gb=0.5),\n",
    "                       description='basic iris classification',\n",
    "                       tags={'quality': 'good', 'type': 'classification'})\n",
    "    model.add_properties({\"accuracy\":model_accuracy,\"model_type\":model_type})\n",
    "    model.experiment_name=experiment_name\n",
    "    model.run_id = run_id\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Pipeline Publish and Schedule\n",
    "train_pipeline.py needs to be modified to perform publishing (change pipeline=True) to be published from the automated run. The below cells can be performed interactively after the pipeline above is submitted if desired"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = iris_train_pipeline.publish(name=\"iris_training_demo\", description=\"Iris Classification Demo\", continue_on_step_failure=True)\n",
    "published_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core.schedule import ScheduleRecurrence, Schedule\n",
    "\n",
    "recurrence = ScheduleRecurrence(frequency=\"Day\", interval=1, hours=[22], minutes=[30]) # Runs every day at 10:30pm\n",
    "\n",
    "schedule = Schedule.create(workspace=ws, name=\"iris_training_demo_schedule\",\n",
    "                           pipeline_id=published_pipeline.id, \n",
    "                           experiment_name='iris_training_demo_daily_schedule_run',\n",
    "                           recurrence=recurrence,\n",
    "                           wait_for_provisioning=True,\n",
    "                           description=\"iris training demo daily Schedule Run\")"
   ]
  }
 ]
}